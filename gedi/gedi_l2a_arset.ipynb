{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NaiaraSPinto/VegMapper/blob/master/gedi/gedi_l2a_arset.ipynb)\n"
      ],
      "metadata": {
        "id": "7TwP0_Z-ZGyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Install packages and import dependencies"
      ],
      "metadata": {
        "id": "KtlyJGDb9x6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "4oHmHuihrNJb",
        "outputId": "3add5c95-95da-43fd-9068-04297eb2c992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.5/70.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for curlify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "pydantic-settings 2.11.0 requires python-dotenv>=0.21.0, but you have python-dotenv 0.20.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "google-adk 1.16.0 requires python-dotenv<2.0.0,>=1.0.0, but you have python-dotenv 0.20.0 which is incompatible.\n",
            "google-adk 1.16.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q geoviews earthaccess harmony-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from harmony import BBox, Client, Collection, Request, CapabilitiesRequest\n",
        "from datetime import datetime\n",
        "import json\n",
        "import earthaccess\n",
        "import geopandas as gp\n",
        "import os\n",
        "from IPython.display import JSON\n",
        "import h5py\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point\n",
        "import ast\n",
        "import subprocess\n",
        "import requests\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "M2b0JhrdrlXH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- Authenticate with your NASA Earth Data credentials"
      ],
      "metadata": {
        "id": "3wne6rqz96OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth = earthaccess.login(persist=True)"
      ],
      "metadata": {
        "id": "n5QYdolgrqOA",
        "outputId": "cd759b92-7e0d-4554-ae97-2e59f500935f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Earthdata Login username: simbarashejombo@gmail.com\n",
            "Enter your Earthdata password: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Define your Area Of Interest by dragging a GEOJSON into your local folder\n",
        "You may need to simplify your polygon"
      ],
      "metadata": {
        "id": "4-wJmtMK-YMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_site = input(\"Enter the path to your GeoJSON polygon file: \")\n",
        "\n",
        "try:\n",
        "    with open(my_site) as f:\n",
        "        geojson_polygon = json.load(f)\n",
        "    print(\"GeoJSON loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {my_site}\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Invalid GeoJSON format in file: {https://github.com/NaiaraSPinto/VegMapper/blob/master/gedi/sao_jose.geojson}\")"
      ],
      "metadata": {
        "id": "mq8S_rX7-it_",
        "outputId": "f3ff7384-77f3-4f7c-d510-82546ae28b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to your GeoJSON polygon file: https://github.com/NaiaraSPinto/VegMapper/blob/master/gedi/sao_jose.geojson\n",
            "File not found: https://github.com/NaiaraSPinto/VegMapper/blob/master/gedi/sao_jose.geojson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- Define the temporal range of your search\n",
        "GEDI data availability:\n",
        "*   April 2019 - March 2023\n",
        "*   April 2024 - Present\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqQWeK_vSgrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_str = input(\"Enter start date (YYYY-MM-DD): \")\n",
        "stop_str = input(\"Enter stop date (YYYY-MM-DD): \")\n",
        "\n",
        "# Convert input strings to datetime objects\n",
        "try:\n",
        "    temporal_range = {\n",
        "        'start': datetime.strptime(start_str, \"%Y-%m-%d\"),\n",
        "        'stop': datetime.strptime(stop_str, \"%Y-%m-%d\")\n",
        "    }\n",
        "    print(\"Temporal range set to:\", temporal_range)\n",
        "except ValueError:\n",
        "    print(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
        "output_folder = input(\"Enter the output folder where you wish to save your results:\")"
      ],
      "metadata": {
        "id": "a6P-27_PSaHo",
        "outputId": "0e96b07b-cf2a-4b37-fe2e-ecddbb50bfca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temporal range set to: {'start': datetime.datetime(2019, 1, 1, 0, 0), 'stop': datetime.datetime(2025, 10, 1, 0, 0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5- Call the Harmony Service to subset GEDI granules for our Area Of Interest"
      ],
      "metadata": {
        "id": "HT_B--Hb-oAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "harmony_client = Client(auth=(auth.username, auth.password))\n",
        "capabilities_request = CapabilitiesRequest(short_name='GEDI02_A')\n",
        "capabilities = harmony_client.submit(capabilities_request)\n",
        "concept_id = capabilities['conceptId']\n",
        "\n",
        "request = Request(\n",
        "    collection = Collection(id=concept_id),\n",
        "    shape = my_site,\n",
        "    temporal = temporal_range\n",
        ")\n",
        "task = harmony_client.submit(request)\n",
        "print(f'Harmony request ID: {task}')\n",
        "print(f'Processing your Harmony request:')\n",
        "task_json = harmony_client.result_json(task, show_progress=True)"
      ],
      "metadata": {
        "id": "V8oEfy2e-MbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6- Save the list of subsetted files\n",
        "The list contains the remote location of files containing GEDI shots in H5 format. Here, we are only retrieving a list of file locations, not the files themselves."
      ],
      "metadata": {
        "id": "foioz9Ak-xHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h5_files = [link['href'] for link in task_json['links'] if link['href'].endswith('.h5')]\n",
        "with open(os.path.join(output_folder, 'h5_files.txt'), 'w') as f:\n",
        "    for h5_file in h5_files:\n",
        "        f.write(h5_file + '\\n')\n",
        "\n",
        "print(\"H5 file links saved to h5_files.txt\")"
      ],
      "metadata": {
        "id": "CxquWYx27qQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7- User-defined quality and height criteria\n",
        "Here are some commonly-used criteria:\n",
        "*   Min RH95 can be used to **exclude bare ground**\n",
        "*   Sensitivity is the the maximum canopy cover through which the LiDAR can detect the ground with 90% probability, and it is useful in areas of **dense vegetation**\n",
        "*   Night time shots can be selected to maximize **signal-to-noise ratio**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hz7psgMiXU5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sensitivity\n",
        "while True:\n",
        "    min_sens_input = input(\"Enter minimum sensitivity value (0.0-0.9): \")\n",
        "    try:\n",
        "        min_sens = float(min_sens_input)\n",
        "        # Check if the float is within the desired range\n",
        "        if 0.0 <= min_sens <= 0.9:\n",
        "            print(f\"Minimum sensitivity set to: {min_sens}\")\n",
        "            break  # Exit the loop if input is valid\n",
        "        else:\n",
        "            print(\"Error: The value must be between 0.0 and 0.9.\")\n",
        "    except ValueError:\n",
        "        print(\"Error: Invalid input. Please enter a numerical value.\")\n",
        "\n",
        "#min RH95\n",
        "while True:\n",
        "    min_height_input = input(\"Enter minimum RH95 value (0-5): \")\n",
        "    try:\n",
        "        min_height = int(min_height_input)\n",
        "        # Check if the integer is within the desired range\n",
        "        if 0 <= min_height <= 5:\n",
        "            print(f\"Minimum height set to: {min_height}\")\n",
        "            break # Exit the loop if input is valid\n",
        "        else:\n",
        "            print(\"Error: The value must be between 0 and 5.\")\n",
        "    except ValueError:\n",
        "        print(\"Error: Invalid input. Please enter a numerical value.\")\n",
        "\n",
        "#night time only\n",
        "try:\n",
        "    night_only = ast.literal_eval(input(\"Enter True or False for night only filtering: \"))\n",
        "    if isinstance(night_only, bool):\n",
        "        print(f\"The boolean value is: {night_only}\")\n",
        "        print(f\"The type is: {type(night_only)}\")\n",
        "    else:\n",
        "        print(\"Invalid input. The input must be 'True' or 'False'.\")\n",
        "except (ValueError, SyntaxError):\n",
        "    print(\"Invalid input. The input must be 'True' or 'False'.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TrShJcjTXUHO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8- Function to filter GEDI L2A shots\n",
        "For each H5 file, download from the DAAC, apply the user-specified filtering, and save results as a local CSV."
      ],
      "metadata": {
        "id": "oZVHb6FDyZEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the main function\n",
        "def extract_gedi_rh_metrics_from_urls(file_list_txt, csv_file, beams=None,\n",
        "                                      min_sensitivity=0.9, min_rh95=0,\n",
        "                                      night=False):\n",
        "    \"\"\"\n",
        "    Reads a list of HTTPS GEDI HDF5 file URLs, downloads each file completely,\n",
        "    extracts RH metrics for specified beams, filters by sensitivity, RH95,\n",
        "    and optionally by solar elevation (nighttime), and saves all shots to a CSV.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_list_txt : str\n",
        "        Path to a text file containing one HTTPS URL per line.\n",
        "    csv_file : str\n",
        "        Output CSV file path.\n",
        "    beams : list, optional\n",
        "        List of beam names to extract. Defaults to the four full-power beams.\n",
        "    min_sensitivity : float, optional\n",
        "        Minimum acceptable sensitivity (default: 0.95)\n",
        "    min_rh95 : float, optional\n",
        "        Minimum acceptable RH95 value (default: 0)\n",
        "    night : bool, optional\n",
        "        If True, select only shots where solar_elevation < 0 (nighttime)\n",
        "    \"\"\"\n",
        "    if beams is None:\n",
        "        beams = ['BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011']\n",
        "\n",
        "    # Read list of URLs\n",
        "    with open(file_list_txt, 'r') as f:\n",
        "        h5_urls = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for url in h5_urls:\n",
        "        print(f\"\\nğŸ“¥ Downloading {url} ...\")\n",
        "        try:\n",
        "            response = requests.get(url, timeout=300)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".h5\", delete=False) as tmp:\n",
        "                tmp.write(response.content)\n",
        "                tmp_path = tmp.name\n",
        "\n",
        "            with h5py.File(tmp_path, 'r') as f:\n",
        "                for beam_name in beams:\n",
        "                    if beam_name not in f:\n",
        "                        print(f\"  âš ï¸ Beam {beam_name} not found in {url}\")\n",
        "                        continue\n",
        "\n",
        "                    beam = f[beam_name]\n",
        "\n",
        "                    # Check datasets required for GEDI L2A v2.1+\n",
        "                    required = ['lat_lowestmode', 'lon_lowestmode', 'rh', 'shot_number', 'solar_elevation']\n",
        "                    if not all(k in beam for k in required):\n",
        "                        print(f\"  âš ï¸ Missing required datasets in {beam_name}\")\n",
        "                        continue\n",
        "\n",
        "                    # Try to access sensitivity safely\n",
        "                    sensitivity = None\n",
        "                    if 'QA' in beam and 'sensitivity' in beam['QA']:\n",
        "                        sensitivity = beam['QA/sensitivity'][:]\n",
        "                    elif 'sensitivity' in beam:\n",
        "                        sensitivity = beam['sensitivity'][:]\n",
        "                    else:\n",
        "                        print(f\"  âš ï¸ Sensitivity missing in {beam_name}, skipping beam\")\n",
        "                        continue\n",
        "\n",
        "                    lat = beam['lat_lowestmode'][:]\n",
        "                    lon = beam['lon_lowestmode'][:]\n",
        "                    shot_num = beam['shot_number'][:]\n",
        "                    rh = beam['rh'][:]\n",
        "                    solar = beam['solar_elevation'][:]\n",
        "\n",
        "                    # Extract selected RH metrics\n",
        "                    rh25 = rh[:, 25]\n",
        "                    rh50 = rh[:, 50]\n",
        "                    rh75 = rh[:, 75]\n",
        "                    rh95 = rh[:, 95]\n",
        "\n",
        "                    # Apply filters\n",
        "                    mask = (sensitivity >= min_sensitivity) & (rh95 >= min_rh95)\n",
        "                    if night:\n",
        "                        mask &= (solar < 0)\n",
        "\n",
        "                    if not mask.any():\n",
        "                        print(f\"  âš™ï¸ No shots passed filters in {beam_name}\")\n",
        "                        continue\n",
        "\n",
        "                    df = pd.DataFrame({\n",
        "                        \"source_url\": url,\n",
        "                        \"beam\": beam_name,\n",
        "                        \"shot_number\": shot_num[mask],\n",
        "                        \"latitude\": lat[mask],\n",
        "                        \"longitude\": lon[mask],\n",
        "                        \"rh25\": rh25[mask],\n",
        "                        \"rh50\": rh50[mask],\n",
        "                        \"rh75\": rh75[mask],\n",
        "                        \"rh95\": rh95[mask],\n",
        "                        \"sensitivity\": sensitivity[mask],\n",
        "                        \"solar_elevation\": solar[mask]\n",
        "                    })\n",
        "\n",
        "                    records.append(df)\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"âŒ Download failed for {url}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {url}: {e}\")\n",
        "        finally:\n",
        "            if 'tmp_path' in locals() and os.path.exists(tmp_path):\n",
        "                os.remove(tmp_path)\n",
        "\n",
        "    # Combine all dataframes\n",
        "    if records:\n",
        "        shots_df = pd.concat(records, ignore_index=True)\n",
        "        shots_df.to_csv(csv_file, index=False)\n",
        "        print(f\"\\nâœ… Total shots saved: {len(shots_df):,}\")\n",
        "        print(f\"âœ… Output file: {csv_file}\")\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ No valid shots extracted.\")\n"
      ],
      "metadata": {
        "id": "VgDJmjGG7DRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9- Run the filter function\n",
        "Results will be saved in a CSV file that can be downloaded into your computer"
      ],
      "metadata": {
        "id": "AHNZT9WDV6sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your GEDI L2A file subset by Harmony\n",
        "gedi_file = input(\"Enter the path to the H5 file list\")\n",
        "out_csv_file = input(\"Enter the path to the output CSV file\")\n",
        "\n",
        "#List of Full Power Beams\n",
        "full_power_beams = ['BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011']\n",
        "\n",
        "#Get the filtering variables\n",
        "min_sens_input = float(min_sens_input)\n",
        "min_height_input = int(min_height_input)\n",
        "night_only = bool(night_only)\n",
        "\n",
        "#Run the function to filter H5 file and extract RH metrics\n",
        "extract_gedi_rh_metrics_from_urls(gedi_file, out_csv_file, beams=full_power_beams,\n",
        "                                      min_sensitivity=min_sens_input, min_rh95=min_height_input,\n",
        "                                      night=night_only)"
      ],
      "metadata": {
        "id": "30bDx6HllyY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}