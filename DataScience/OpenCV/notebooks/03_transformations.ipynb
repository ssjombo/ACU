{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff748443",
   "metadata": {},
   "source": [
    "# OpenCV Geometric Transformations Tutorial\n",
    "\n",
    "This notebook explores geometric transformations using OpenCV, including affine and perspective transformations.\n",
    "\n",
    "## Contents\n",
    "1. [Setup and Installation](#setup)\n",
    "2. [Affine Transformations](#affine)\n",
    "3. [Perspective Transformations](#perspective)\n",
    "4. [Image Warping](#warping)\n",
    "5. [Practical Applications](#applications)\n",
    "6. [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47aeaa",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation {#setup}\n",
    "\n",
    "First, let's import the necessary libraries and our custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install opencv-python numpy matplotlib\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Add our source directory to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from transformations import affine_transforms, perspective_transforms, warping\n",
    "from basic_operations import image_io, display\n",
    "from utils import visualization\n",
    "\n",
    "print(\"✅ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8361ffe8",
   "metadata": {},
   "source": [
    "## 2. Affine Transformations {#affine}\n",
    "\n",
    "Affine transformations preserve points, straight lines, and planes. They include translation, rotation, scaling, and shearing.\n",
    "\n",
    "### 2.1 Translation\n",
    "Moving an image by a specific offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample image\n",
    "image_path = '../sample_images/original/demo_image.jpg'\n",
    "if os.path.exists(image_path):\n",
    "    image = image_io.load_image(image_path)\n",
    "else:\n",
    "    # Create a demo image if sample doesn't exist\n",
    "    image = np.zeros((300, 400, 3), dtype=np.uint8)\n",
    "    cv2.rectangle(image, (50, 50), (150, 150), (255, 0, 0), -1)\n",
    "    cv2.circle(image, (300, 100), 50, (0, 255, 0), -1)\n",
    "    cv2.putText(image, 'Demo', (200, 250), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "# Apply translation\n",
    "tx, ty = 50, 30  # Translation values\n",
    "translated_image = affine_transforms.translate_image(image, tx, ty)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(translated_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Translated (tx={tx}, ty={ty})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50cafd",
   "metadata": {},
   "source": [
    "### 2.2 Rotation\n",
    "Rotating an image around a center point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d897c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation\n",
    "angle = 45  # Rotation angle in degrees\n",
    "center = None  # Use image center if None\n",
    "scale = 1.0   # Scale factor\n",
    "\n",
    "rotated_image = affine_transforms.rotate_image(image, angle, center, scale)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Rotated {angle}°')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6159a",
   "metadata": {},
   "source": [
    "### 2.3 Scaling\n",
    "Resizing an image with different scale factors for x and y axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling\n",
    "scale_x, scale_y = 1.5, 0.8  # Scale factors\n",
    "scaled_image = affine_transforms.scale_image(image, scale_x, scale_y)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(scaled_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Scaled (sx={scale_x}, sy={scale_y})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eab12d",
   "metadata": {},
   "source": [
    "### 2.4 Shearing\n",
    "Applying shear transformation to create a slanted effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58efd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply shearing\n",
    "shear_x, shear_y = 0.3, 0.1  # Shear factors\n",
    "sheared_image = affine_transforms.shear_image(image, shear_x, shear_y)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(sheared_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Sheared (shx={shear_x}, shy={shear_y})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d840b9",
   "metadata": {},
   "source": [
    "### 2.5 Combined Affine Transformation\n",
    "Applying multiple transformations in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom affine transformation matrix\n",
    "# Combine rotation, scaling, and translation\n",
    "center = (image.shape[1]//2, image.shape[0]//2)\n",
    "angle = 30\n",
    "scale = 1.2\n",
    "M_rot_scale = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "# Add translation\n",
    "M_rot_scale[0, 2] += 20  # x translation\n",
    "M_rot_scale[1, 2] += 10  # y translation\n",
    "\n",
    "# Apply transformation\n",
    "combined_image = affine_transforms.apply_affine_transform(image, M_rot_scale)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(combined_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Combined Transformation')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Transformation matrix:\")\n",
    "print(M_rot_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206ed67",
   "metadata": {},
   "source": [
    "## 3. Perspective Transformations {#perspective}\n",
    "\n",
    "Perspective transformations can change the perspective of an image, useful for correcting camera angles or creating artistic effects.\n",
    "\n",
    "### 3.1 Four-Point Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination points for perspective transformation\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Source points (corners of the original image)\n",
    "src_points = np.float32([\n",
    "    [50, 50],      # Top-left\n",
    "    [width-50, 50], # Top-right\n",
    "    [50, height-50], # Bottom-left\n",
    "    [width-50, height-50] # Bottom-right\n",
    "])\n",
    "\n",
    "# Destination points (desired perspective)\n",
    "dst_points = np.float32([\n",
    "    [0, 0],        # Top-left\n",
    "    [width, 0],    # Top-right\n",
    "    [100, height], # Bottom-left (shifted)\n",
    "    [width-100, height] # Bottom-right (shifted)\n",
    "])\n",
    "\n",
    "# Apply perspective transformation\n",
    "perspective_image = perspective_transforms.four_point_transform(image, src_points, dst_points)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].plot(src_points[[0,1,3,2,0], 0], src_points[[0,1,3,2,0], 1], 'r-', linewidth=2)\n",
    "axes[0].set_title('Original with Source Points')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(perspective_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Perspective Transformed')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676faf8",
   "metadata": {},
   "source": [
    "### 3.2 Document Scanning Simulation\n",
    "Simulating the perspective correction often used in document scanning apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84367166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document-like image\n",
    "doc_image = np.ones((400, 300, 3), dtype=np.uint8) * 255\n",
    "cv2.rectangle(doc_image, (20, 20), (280, 380), (0, 0, 0), 2)\n",
    "cv2.putText(doc_image, 'DOCUMENT', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "cv2.putText(doc_image, 'Line 1: Sample text here', (30, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "cv2.putText(doc_image, 'Line 2: More sample text', (30, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "cv2.putText(doc_image, 'Line 3: Additional content', (30, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "# Apply perspective distortion (simulating angled photo)\n",
    "h, w = doc_image.shape[:2]\n",
    "src_rect = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "dst_quad = np.float32([[0, 30], [w-20, 0], [20, h], [w, h-30]])\n",
    "\n",
    "# Create perspective distortion\n",
    "M_distort = cv2.getPerspectiveTransform(src_rect, dst_quad)\n",
    "distorted_doc = cv2.warpPerspective(doc_image, M_distort, (w, h))\n",
    "\n",
    "# Correct the perspective\n",
    "corrected_doc = perspective_transforms.correct_perspective(distorted_doc, dst_quad, src_rect)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(cv2.cvtColor(doc_image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Document')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(distorted_doc, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Distorted (Angled Photo)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(corrected_doc, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Perspective Corrected')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675de83b",
   "metadata": {},
   "source": [
    "## 4. Image Warping {#warping}\n",
    "\n",
    "Image warping allows for more complex deformations including barrel and pincushion distortion corrections.\n",
    "\n",
    "### 4.1 Barrel Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c235233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply barrel distortion correction\n",
    "k1, k2 = 0.2, 0.1  # Distortion coefficients\n",
    "corrected_barrel = warping.correct_barrel_distortion(image, k1, k2)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(corrected_barrel, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Barrel Corrected (k1={k1}, k2={k2})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d07061",
   "metadata": {},
   "source": [
    "### 4.2 Custom Warping\n",
    "Creating custom warp effects using displacement maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ed88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wave distortion effect\n",
    "wave_amplitude = 20\n",
    "wave_frequency = 0.02\n",
    "wave_warped = warping.wave_distortion(image, wave_amplitude, wave_frequency)\n",
    "\n",
    "# Create swirl effect\n",
    "swirl_strength = 1.0\n",
    "swirl_warped = warping.swirl_distortion(image, swirl_strength)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(wave_warped, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Wave Distortion')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(swirl_warped, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Swirl Distortion')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db453ae",
   "metadata": {},
   "source": [
    "## 5. Practical Applications {#applications}\n",
    "\n",
    "### 5.1 Image Registration\n",
    "Aligning two images using feature-based matching and transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two slightly different images for registration demo\n",
    "img1 = image.copy()\n",
    "img2 = affine_transforms.rotate_image(image, 10)\n",
    "img2 = affine_transforms.translate_image(img2, 30, 20)\n",
    "\n",
    "# Perform image registration (simplified version)\n",
    "registered_img = perspective_transforms.register_images(img1, img2)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes[0,0].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Reference Image')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "axes[0,1].set_title('Target Image (Transformed)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[1,0].imshow(cv2.cvtColor(registered_img, cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].set_title('Registered Image')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "# Show difference\n",
    "diff = cv2.absdiff(img1, registered_img)\n",
    "axes[1,1].imshow(cv2.cvtColor(diff, cv2.COLOR_BGR2RGB))\n",
    "axes[1,1].set_title('Difference After Registration')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b4ecf",
   "metadata": {},
   "source": [
    "### 5.2 Panorama Creation\n",
    "Combining multiple images with perspective correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple views for panorama simulation\n",
    "img_left = image[:, :image.shape[1]//2]\n",
    "img_center = image\n",
    "img_right = image[:, image.shape[1]//2:]\n",
    "\n",
    "# Apply slight transformations to simulate different viewpoints\n",
    "img_left = affine_transforms.rotate_image(img_left, -5)\n",
    "img_right = affine_transforms.rotate_image(img_right, 5)\n",
    "\n",
    "# Create panorama (simplified stitching)\n",
    "panorama = perspective_transforms.create_panorama([img_left, img_center, img_right])\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# Show individual images\n",
    "combined_view = np.hstack([\n",
    "    cv2.resize(img_left, (200, 150)),\n",
    "    cv2.resize(img_center, (200, 150)),\n",
    "    cv2.resize(img_right, (200, 150))\n",
    "])\n",
    "axes[0].imshow(cv2.cvtColor(combined_view, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Individual Images')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Show panorama\n",
    "axes[1].imshow(cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Stitched Panorama')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f428d284",
   "metadata": {},
   "source": [
    "## 6. Exercises {#exercises}\n",
    "\n",
    "Try these exercises to practice geometric transformations:\n",
    "\n",
    "### Exercise 1: Create a Photo Booth Effect\n",
    "Apply multiple transformations to create fun photo effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7900ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Photo booth effects\n",
    "def create_photo_booth_effect(img, effect_type):\n",
    "    \"\"\"Create different photo booth style effects.\"\"\"\n",
    "    if effect_type == 'fisheye':\n",
    "        return warping.fisheye_effect(img, strength=1.5)\n",
    "    elif effect_type == 'squeeze':\n",
    "        return affine_transforms.scale_image(img, 0.8, 1.2)\n",
    "    elif effect_type == 'tilt':\n",
    "        return affine_transforms.rotate_image(img, 15)\n",
    "    elif effect_type == 'mirror':\n",
    "        return np.hstack([img, cv2.flip(img, 1)])\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# Apply different effects\n",
    "effects = ['fisheye', 'squeeze', 'tilt', 'mirror']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, effect in enumerate(effects):\n",
    "    row, col = i // 2, i % 2\n",
    "    effect_img = create_photo_booth_effect(image, effect)\n",
    "    axes[row, col].imshow(cv2.cvtColor(effect_img, cv2.COLOR_BGR2RGB))\n",
    "    axes[row, col].set_title(f'{effect.capitalize()} Effect')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60a9cf",
   "metadata": {},
   "source": [
    "### Exercise 2: Perspective Keystone Correction\n",
    "Correct keystone distortion commonly seen in projector displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3295e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Keystone correction\n",
    "def apply_keystone_distortion(img, top_squeeze=0.8):\n",
    "    \"\"\"Apply keystone distortion to simulate projector effect.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # Define keystone distortion points\n",
    "    src_points = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    dst_points = np.float32([\n",
    "        [w*(1-top_squeeze)/2, 0],     # Top-left squeezed\n",
    "        [w*(1+top_squeeze)/2, 0],     # Top-right squeezed  \n",
    "        [0, h],                       # Bottom-left normal\n",
    "        [w, h]                        # Bottom-right normal\n",
    "    ])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    return cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "def correct_keystone(img, top_squeeze=0.8):\n",
    "    \"\"\"Correct keystone distortion.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # Reverse the keystone transformation\n",
    "    src_points = np.float32([\n",
    "        [w*(1-top_squeeze)/2, 0],\n",
    "        [w*(1+top_squeeze)/2, 0],\n",
    "        [0, h],\n",
    "        [w, h]\n",
    "    ])\n",
    "    dst_points = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    return cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "# Apply and correct keystone distortion\n",
    "keystone_distorted = apply_keystone_distortion(image, 0.6)\n",
    "keystone_corrected = correct_keystone(keystone_distorted, 0.6)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(keystone_distorted, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Keystone Distorted')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(keystone_corrected, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Keystone Corrected')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5a474",
   "metadata": {},
   "source": [
    "### Exercise 3: Transformation Pipeline\n",
    "Create a complete transformation pipeline with multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Transformation pipeline\n",
    "def transformation_pipeline(img, params):\n",
    "    \"\"\"Apply a series of transformations based on parameters.\"\"\"\n",
    "    result = img.copy()\n",
    "    \n",
    "    for transform in params:\n",
    "        transform_type = transform['type']\n",
    "        \n",
    "        if transform_type == 'rotate':\n",
    "            result = affine_transforms.rotate_image(result, transform['angle'])\n",
    "        elif transform_type == 'scale':\n",
    "            result = affine_transforms.scale_image(result, transform['sx'], transform['sy'])\n",
    "        elif transform_type == 'translate':\n",
    "            result = affine_transforms.translate_image(result, transform['tx'], transform['ty'])\n",
    "        elif transform_type == 'perspective':\n",
    "            result = perspective_transforms.four_point_transform(\n",
    "                result, transform['src_points'], transform['dst_points']\n",
    "            )\n",
    "        elif transform_type == 'warp':\n",
    "            if transform['warp_type'] == 'wave':\n",
    "                result = warping.wave_distortion(result, transform['amplitude'], transform['frequency'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define transformation pipeline\n",
    "pipeline_params = [\n",
    "    {'type': 'rotate', 'angle': 10},\n",
    "    {'type': 'scale', 'sx': 1.1, 'sy': 0.9},\n",
    "    {'type': 'translate', 'tx': 20, 'ty': -10},\n",
    "    {'type': 'warp', 'warp_type': 'wave', 'amplitude': 10, 'frequency': 0.01}\n",
    "]\n",
    "\n",
    "# Apply pipeline\n",
    "pipeline_result = transformation_pipeline(image, pipeline_params)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(pipeline_result, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Pipeline Result')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Transformation pipeline applied:\")\n",
    "for i, transform in enumerate(pipeline_params, 1):\n",
    "    print(f\"{i}. {transform['type']}: {transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d153a2a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored:\n",
    "\n",
    "1. **Affine Transformations**: Translation, rotation, scaling, shearing, and combinations\n",
    "2. **Perspective Transformations**: Four-point transforms, document correction, image registration\n",
    "3. **Image Warping**: Barrel distortion correction, wave effects, swirl effects\n",
    "4. **Practical Applications**: Image registration, panorama creation, perspective correction\n",
    "5. **Advanced Techniques**: Photo booth effects, keystone correction, transformation pipelines\n",
    "\n",
    "### Key Takeaways:\n",
    "- Affine transformations preserve parallel lines and ratios of distances\n",
    "- Perspective transformations can correct camera angles and create 3D effects\n",
    "- Image warping enables complex distortion corrections and artistic effects\n",
    "- Transformation matrices can be combined for complex operations\n",
    "- Real-world applications include document scanning, panorama stitching, and AR/VR\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different transformation parameters\n",
    "- Try combining multiple transformations\n",
    "- Apply these techniques to your own images\n",
    "- Explore advanced warping techniques for specific use cases"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
